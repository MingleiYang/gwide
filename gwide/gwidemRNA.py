#!/usr/bin/env python
__author__ = 'Tomasz Turowski'
__copyright__	= "Copyright 2015"
__version__		= "2.0"
__credits__		= ["Tomasz Turowski"]
__email__		= "twturowski@gmail.com"
__status__		= "Production"

import argparse, os
import gwide.methods as gtm
from gwide.Classes.mRNAFromConcat import *

""" Script working with concat file generated by pileupsToConcat.py script. Read concat file and according to options.
Can plot intron, and peaks found by pypeaks script."""

def mRNA():
    usage = "Usage: To create input concat file run novo2concat.py"
    parser = argparse.ArgumentParser(usage=usage)

    files = parser.add_argument_group('Options for input files')
    files.add_argument("-g", "--gtf_file", dest="gtf_file", help="Provide the path to your gtf file.",
                     type=str, default=None)
    files.add_argument("-i", "--input_file", dest="input_file", help="Provide the path to your concat file. REQUIRED.",
                     metavar="FILE", default=None, required=True)
    files.add_argument("--5flank", dest="five_prime_flank", type=int, help="Set up 5 prime flank in pileup file. Default = 0", default=0)
    files.add_argument("--3flank", dest="three_prime_flank", type=int, help="Set up 3 prime flank in pileup file. Default = 0", default=0)

    universal = parser.add_argument_group('Universal options')
    universal.add_argument("-t", "--hits_threshold", dest="hits_threshold", type=int, help="Set up threshold for pileup. Default 0 reads",
                      default=0)
    universal.add_argument("-n", "--normalized", dest="normalized", action="store_true", help="Use when you want to work on data normalized 'reads per Milion'. Default: False", default=False)

    output = parser.add_argument_group('Options for output files')
    output.add_argument("-p", "--prefix", dest="out_prefix", type=str, help="Prefix for output files. Default to standard output. Not supported for -o ratio.", default=None)
    output.add_argument("-o", dest="output_files", choices=['bind'], help="Select from following options:"
                        "(1) Print binding windows in fasta file", default="bind")
    output.add_argument("--peaks", dest="print_peaks", action="store_true", help="print peaks on plots. Default: False", default=False)
    output.add_argument("--valleys", dest="print_valleys", action="store_true", help="print valleys on plots. Default: False", default=False)

    special = parser.add_argument_group('Special options for some -o choices')
    special.add_argument("--lookahead", dest="lookahead", type=int, help="Set up lookahead parameter for pypeaks function. Default = 20", default=20)
    special.add_argument("-w", "--window", dest="window", type=int, help="Set up size of window for bind calculation (-o bind). Default: 10",
                      default=10)
    # special.add_argument("--ntotal", dest="ntotal", action="store_true", help="Normalize data to sum of all reads (sum = 1). Default: False", default=False)
    # special.add_argument("--nmax", dest="nmax", action="store_true", help="Normalize data to maximal value (max = 1). Default: False", default=False)
    # special.add_argument("-a", dest="to_divide", type=str, help="experiment to divide by -b (-o fig_ratio)",
    #                   default=None)
    # special.add_argument("-b", dest="divisor", type=str, help="experiment being divisor for -a (-o fig_ratio)",
    #                   default=None)
    options = parser.parse_args()

    #checking input
    input_file = options.input_file

    #preparing naming of output files
    if options.out_prefix:
        prefix = options.out_prefix+'_'
    else:
        prefix = str()
    if options.normalized == True:
        prefix = 'normalized_'+prefix

    data = mRNAFromConcat(gtf_file=gtm.getGTF(options.gtf_file), five_prime_flank=options.five_prime_flank, three_prime_flank=options.three_prime_flank,
                          hits_threshold=options.hits_threshold, lookahead=options.lookahead, prefix=prefix, npM=options.normalized)



    if options.output_files == "bind":
        #reading csv file
        data.read_csv(input_file, use='deletions')
        #calculating readthrough, details, normalize
        data.calculate(details=options.details, ntotal=options.ntotal, nmax=options.nmax)

    print '# Done.'

